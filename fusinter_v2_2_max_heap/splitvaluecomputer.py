import numpy as np
from numba import jit

from .orderedHeap import OrderedHeap


@jit(nopython=True)
def shannon_entropy(input_column: np.ndarray, alpha, lam, m, n) -> float:
    """
    Implementation of the Shannon Entropy for one column formula on page 12 of the paper
    :param input_column: a numpy array in the form of a column generated by FUSINTER
    :param alpha: a scalar weight parameter (see the paper)
    :param lam: a scalar weight parameter (see the paper)
    :m: the number of classes
    :n: sum of all components of the table where column is from
    :return: a scalar value for estimation splits
    """
    col_sum = 0
    n_j = np.sum(input_column)
    col_fac = alpha * n_j / n
    for i in range(m):
        p = (input_column[i] + lam) / (n_j + m * lam)
        col_sum += -(p * np.log2(p))
    result = col_fac * col_sum + (1 - alpha) * m * lam / n_j

    return result


class SplitValueComputer:
    def __init__(self, table: np.ndarray, split_points: np.ndarray, alpha: float, lam: float):
        assert alpha > 0
        assert lam > 0

        self.table = table
        self.alpha = alpha
        self.lam = lam

        # compute necessary values for updating the split values
        self.m = table.shape[0]
        self.k = table.shape[1]
        self.n = np.sum(table)
        self.entropy_func = lambda x: shannon_entropy(x, self.alpha, self.lam, self.m, self.n)

        self.heap = OrderedHeap()
        pos = -1
        for col_idx in range(table.shape[1] - 1):
            data = {
                "split_point": split_points[col_idx],
                "left_column": table[:, col_idx],
                "right_column": table[:, col_idx + 1],
                "pos": col_idx
            }
            pos = self.heap.insert(
                pos,
                [np.round(self.compute_delta(table[:, col_idx], table[:, col_idx + 1]),15), -col_idx],
                data,
            )

    def compute_delta(self, column1: np.ndarray, column2: np.ndarray):
        delta = 0.
        delta += self.entropy_func(column1)
        delta += self.entropy_func(column2)
        delta -= self.entropy_func(column1 + column2)

        return delta

    def get_max_delta(self):
        return self.heap.array[0].value[0]

    def merge_max(self):
        if len(self.heap) == 0:
            raise Exception("the heap is already empty")

        max_element = self.heap.array[0]
        left_neighbor = None
        right_neighbor = None

        if max_element.previous_idx != -1:
            left_neighbor = self.heap.array[max_element.previous_idx]

        if max_element.next_idx != -1:
            right_neighbor = self.heap.array[max_element.next_idx]

        merged_column = max_element.data["left_column"] + max_element.data["right_column"]

        self.heap.delete_element(0)

        if left_neighbor:
            left_neighbor.data["right_column"] = merged_column
            left_neighbor.value[0] = np.round(self.compute_delta(left_neighbor.data["left_column"],
                                                     left_neighbor.data["right_column"]), 15)
            self.heap.heapify(self.heap.where_is_element(left_neighbor))

        if right_neighbor:
            right_neighbor.data["left_column"] = merged_column
            right_neighbor.value[0] = np.round(self.compute_delta(right_neighbor.data["left_column"],
                                                      right_neighbor.data["right_column"]),15)
            self.heap.heapify(self.heap.where_is_element(right_neighbor))

    def get_splits(self):
        splits = []
        for el in self.heap.array:
            splits.append(el.data["split_point"])

        splits.sort()
        return splits
